# fetch_any_dict.py
# encoding: utf-8
'''
# -------------------------------------------------------------------------
# ä½œç”¨ï¼š
# å½“å‰è„šæœ¬ç”¨äºæ‹‰å–ä¸‡è±¡è¯åº“çš„æœ€è¿‘æ›´æ–°ï¼Œå¹¶è¿›è¡Œã€Œè½¬æ¢ â­ åˆå¹¶ â­ æ’åºã€å¤„ç†ï¼Œä»¥
# ç”Ÿæˆæ‰€éœ€çš„äº”ç¬”ã€è™ç å¸¸è§„åŠæ•´å¥è¯åº“ã€æ‹¼éŸ³è¯åº“
# 
# --- å…¶ä»–è¯´æ˜ ---
# å…¶å®ç¨å¾®ä¿®æ”¹ä¸€ä¸‹å½“å‰è„šæœ¬ï¼Œå¯ä»¥è·å¾—æ›´å¤šè½¬æ¢åŠŸèƒ½ï¼Œæœ‰å…´è¶£çš„æœ‹å‹å¯ä»¥è‡ªè¡Œæ‰©å±•
# -------------------------------------------------------------------------
'''
import os
import sys
import stat
import re
import shutil
import subprocess
import hashlib
from pathlib import Path
import threading
from timer import timer
from is_chinese_char import is_chinese_char
from progress import format_progress_bar
from tiger_map import tiger_map
from wubi86_8105_map import wubi86_8105_map
from header import get_header_ext
from header import get_header_common
from collections import defaultdict
import zipfile
import urllib.request
from datetime import datetime, timedelta, timezone

def run_git_command(command, cwd=None):
    """æ‰§è¡Œgitå‘½ä»¤å¹¶è¿”å›æ˜¯å¦æˆåŠŸ"""
    try:
        result = subprocess.run(["git"] + command, cwd=cwd, check=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)
        return {
            "success": True,
            "stdout": result.stdout.strip(),
            "stderr": result.stderr.strip()
        }
    except subprocess.CalledProcessError:
        return False

def ask_yes_no(question, timeout=5):
    '''
    è¯¢é—®æ˜¯å¦ç»§ç»­æ“ä½œ  
    question - å…·ä½“è¯·æ±‚æè¿°  
    timeout - é»˜è®¤è¶…è¿‡ 5s è‡ªåŠ¨å–æ¶ˆ
    '''
    answer = [None]  # ä½¿ç”¨åˆ—è¡¨ä»¥ä¾¿åœ¨åµŒå¥—å‡½æ•°ä¸­ä¿®æ”¹
    def input_thread():
        answer[0] = input(f"{question} ? (y/n) y: ").strip().lower() or "y"

    print(f"\n--- é»˜è®¤ {timeout} ç§’åå–æ¶ˆæ“ä½œ ---")
    thread = threading.Thread(target=input_thread)
    thread.daemon = True
    thread.start()
    thread.join(timeout)
    if answer[0] in ("y", "yes"):
        print("ğŸ”œ  Â» ç»§ç»­æ“ä½œ Â¦ å³å°†å¼€å§‹æ‰§è¡Œ...")
        return True
    else:
        print('\nğŸ‰  Â» å–æ¶ˆæ“ä½œ Â¦ ç¥ä½ ä½¿ç”¨æ„‰å¿«')
        return False

def remove_readonly(func, path, exc):
    """
    æ¸…é™¤åªè¯»å±æ€§å¹¶é‡æ–°å°è¯•åˆ é™¤ã€‚
    """
    try:
        os.chmod(path, stat.S_IWRITE)
        func(path)
    except Exception as e:
        print(f"Error removing {path}: {e}")

def force_delete(path):
    """
    å¼ºåˆ¶åˆ é™¤æ–‡ä»¶æˆ–æ–‡ä»¶å¤¹ï¼Œå¿½ç•¥æƒé™é™åˆ¶ã€‚
    """
    if not os.path.exists(path):
        return True
    try:
        if os.path.isfile(path) or os.path.islink(path):
            os.chmod(path, stat.S_IWRITE)
            os.remove(path)
        elif os.path.isdir(path):
            shutil.rmtree(path, onexc=remove_readonly)
        return True
    except Exception as e:
        print(f"Error deleting {path}: {e}")
        return False


def sync_repository(repo_url, local_path):
    """åŒæ­¥Gitä»“åº“ï¼ˆå…‹éš†æ—¶åªè·å–æœ€æ–°ç‰ˆæœ¬ï¼‰"""
    git_dir = local_path / ".git"
    backup_path = local_path.with_suffix('.bak')
    sync_success = True

    if git_dir.exists():
        print(f"ä»“åº“å·²å­˜åœ¨äº {local_path}")
        print(f"--- æ‹‰å–æœ€æ–°æ›´æ–° ---")
        print(f"ğŸ”œ  æ­£åœ¨æ‹‰å–æœ€æ–°æ›´æ–°...")
        pull_result = run_git_command(["pull", "--depth=1"], cwd=local_path)
        if pull_result and pull_result['success']:
            # print("è¾“å‡ºä¿¡æ¯:", pull_result["stdout"])
            if 'Already up to date' in pull_result["stdout"]:
                print("âœ…  Â» æ— éœ€è½¬æ¢ Â¦ ä»“åº“æ²¡æœ‰æ–°çš„æäº¤")
                # sync_success = False
                sync_success = ask_yes_no(f"ğŸ””  æ˜¯å¦ç»§ç»­æ‰§è¡Œè½¬æ¢æ“ä½œ")
                # if sync_success:
                #     print("ğŸ”œ  Â» ç»§ç»­è½¬æ¢ Â¦ å³å°†å¼€å§‹è½¬æ¢...")
                # else:
                #     print("\nğŸ‰  Â» ä¸å†è½¬æ¢ Â¦ ç¥ä½ ä½¿ç”¨æ„‰å¿«")
            else:
                print("âœ…  Â» æ‹‰å–æ›´æ–°æˆåŠŸ")
        else:
            print("ğŸš«  Â» æ‹‰å–æ›´æ–°å¤±è´¥")
            sync_success = False
            if local_path.exists():
                # if backup_path.exists():
                force_delete(backup_path)
                local_path.rename(backup_path)
                print(f"âœ…  Â» å½“å‰ä»“åº“å·²å¤‡ä»½ä¸º { backup_path }")
            print(f"--- é‡æ–°æµ…å…‹éš† ---")
            sync_success = sync_repository(repo_url, local_path)
    else:
        print(f"ğŸ”œ  æ­£åœ¨æµ…å…‹éš† {repo_url}...")
        local_path.parent.mkdir(parents=True, exist_ok=True)
        
        if run_git_command(["clone", "--depth=1", repo_url, str(local_path)]):
            print(f"âœ…  Â» ä»“åº“å·²æµ…å…‹éš†åˆ° {local_path}")
            sync_success = True
        else:
            print("ğŸš«  Â» å…‹éš†ä»“åº“å¤±è´¥")
            if backup_path.exists():
                print(f"--- å¼€å§‹æ¢å¤ä»“åº“ ---")
                # if local_path.exists():
                force_delete(local_path)
                backup_path.rename(local_path)
                print(f"âœ…  Â» ä»“åº“æ¢å¤æˆåŠŸ {local_path}")
                sync_success = False
    return sync_success


def get_wubi_code(word: str) -> str:
    """å°†æ±‰å­—è½¬æ¢ä¸ºäº”ç¬”ç¼–ç """
    if code_type.startswith("20"):
        # ^ å¸¸è§„ç¼–ç 
        if len(word) == 1:
            return f'{wubi86_8105_map[word]}'
        elif len(word) == 2:
            return f'{wubi86_8105_map[word[0]][:2]}{wubi86_8105_map[word[1]][:2]}'
        elif len(word) == 3:
            return f'{wubi86_8105_map[word[0]][0]}{wubi86_8105_map[word[1]][0]}{wubi86_8105_map[word[2]][:2]}'
        elif len(word) >= 4:
            return f'{wubi86_8105_map[word[0]][0]}{wubi86_8105_map[word[1]][0]}{wubi86_8105_map[word[2]][0]}{wubi86_8105_map[word[len(word) - 1]][0]}'
    else:
        # ^ æ•´å¥ç¼–ç 
        code_parts = []
        for char in word:
            wubi_code = wubi86_8105_map[char]
            if len(wubi_code) == 3:
                code_parts.append(f"{wubi_code[:2]};{wubi_code[2:]}z")
            else:
                code_parts.append(f"{wubi_code[:2]};{wubi_code[2:]}")
        return ' '.join(code_parts)

def get_tiger_code(word: str) -> str:
    """å°†æ±‰å­—è½¬æ¢ä¸ºè™ç ç¼–ç """
    if code_type.startswith("30"):
        # ^ å¸¸è§„ç¼–ç 
        if len(word) == 1:
            return f'{tiger_map[word]}'
        elif len(word) == 2:
            return f'{tiger_map[word[0]][:2]}{tiger_map[word[1]][:2]}'
        elif len(word) == 3:
            return f'{tiger_map[word[0]][0]}{tiger_map[word[1]][0]}{tiger_map[word[2]][:2]}'
        elif len(word) >= 4:
            return f'{tiger_map[word[0]][0]}{tiger_map[word[1]][0]}{tiger_map[word[2]][0]}{tiger_map[word[len(word) - 1]][0]}'
    else:
        # ^ æ•´å¥ç¼–ç 
        code_parts = []
        for char in word:
            tiger_code = tiger_map[char]
            if len(tiger_code) == 3:
                code_parts.append(f"{tiger_code[:2]};{tiger_code[2:]}_")
            else:
                code_parts.append(f"{tiger_code[:2]};{tiger_code[2:]}")
        return ' '.join(code_parts)

def get_pinyin_code(code: str) -> str:
    """å°†æ±‰å­—è½¬æ¢ä¸ºæ‹¼éŸ³ + è¾…åŠ©ç ç¼–ç ï¼ˆå¯é€‰ï¼‰"""
    code_parts = []
    for _code in code.split(' '):
        _cc = _code.split(';')
        fuzhuma = _cc[int(code_type[-1])] if not code_type.endswith('0') else ''
        code_parts.append(f'{_cc[0]}{';' if fuzhuma else ''}{fuzhuma}')

    return ' '.join(code_parts)


@timer
def convert(src_dir: Path, out_dir: Path, file_endswith_filter: str) -> None:
    """å°†æ‹¼éŸ³è¯åº“è½¬æ¢ä¸ºäº”ç¬”è¯åº“"""
    out_dir.mkdir(parents=True, exist_ok=True)
    tab_split_re = re.compile(r'\t+')

    for file_num, file_path in enumerate(src_dir.glob(f'*{file_endswith_filter}'), 1):
        print(f'â˜‘ï¸  å·²åŠ è½½ç¬¬ {file_num} ä»½ç è¡¨ Â» {file_path.name}')

        valid_entries = set()
        invalid_line_count = 0

        res_dict_word_weight = {}

        # é¢„å¤„ç†ï¼Œè·å–æƒé‡å­—çš„æœ€å¤§æƒé‡æ˜ å°„
        with open(file_path, 'r', encoding='utf-8') as fp:
            for line in fp:
                line = line.strip()
                if not line or not is_chinese_char(line[0]):
                    continue

                parts = tab_split_re.split(line)
                if len(parts) < 3:
                    continue
                word, _, weight = parts[0], parts[1], parts[2]

                # å°†æƒé‡è½¬æ¢ä¸ºæ•´æ•°ä»¥ä¾¿æ¯”è¾ƒ
                current_weight = int(weight)
                # å¦‚æœå­—ä¸å­˜åœ¨äºå­—å…¸ä¸­ï¼Œæˆ–è€…å½“å‰æƒé‡æ›´å¤§ï¼Œåˆ™æ›´æ–°å­—å…¸
                if word not in res_dict_word_weight or current_weight > res_dict_word_weight[word]:
                    res_dict_word_weight[word] = current_weight


        with open(file_path, 'r', encoding='utf-8') as f:
            for line in f:
                line = line.strip()
                if not line or not is_chinese_char(line[0]):
                    continue

                parts = tab_split_re.split(line)
                if len(parts) < 3:
                    continue

                word, code, weight = parts[0], parts[1], parts[2]
                
                if word_length_limit > 0 and len(word) > word_length_limit:
                    # print(f"è¿‡æ»¤æ‰é•¿è¯è¯­: {word} (é•¿åº¦: {len(word)})")
                    continue
                
                # 8105 è¿‡æ»¤å™¨å¼€å…³ - is_filter_8105
                if is_filter_8105 and any(char not in wubi86_8105_map for char in word):
                    continue

                try:
                    if code_type.startswith("1"):
                        pinyin_code = get_pinyin_code(code)
                        valid_entries.add(f"{word}\t{pinyin_code}\t{res_dict_word_weight[word]}\n")
                    elif code_type.startswith("2"):
                        wubi_code = get_wubi_code(word)
                        valid_entries.add(f"{word}\t{wubi_code}\t{res_dict_word_weight[word]}\n")
                    else:
                        tiger_code = get_tiger_code(word)
                        valid_entries.add(f"{word}\t{tiger_code}\t{res_dict_word_weight[word]}\n")
                except KeyError:
                    invalid_line_count += 1

        if valid_entries:
            output_path = out_dir / f"{file_path.stem}.yaml"
            with open(output_path, 'w', encoding='utf-8') as o:
                o.writelines(get_header_common(f"{file_path.stem}.yaml"))
                o.writelines(sorted(valid_entries))

            # print(f"  æˆåŠŸè½¬æ¢ {len(valid_entries)} æ¡è®°å½•ï¼Œè·³è¿‡ {invalid_line_count} æ¡æ— æ•ˆè®°å½•")


@timer
def filter_8105(src_dir: Path, out_file: Path):
    """è¿‡æ»¤å¹¶åˆå¹¶äº”ç¬”ç è¡¨ï¼Œä¿æŒæŒ‰è¯é•¿æ’åº"""
    dict_num = 0
    res_dict = {}
    res_dict_code = defaultdict(set)
    tab_split_re = re.compile(r'\t+')
    word_len_groups = {}
    
    # æŒ‰è¯é•¿åˆ†ç»„å¤„ç†
    for filepath in src_dir.iterdir():
        if filepath.is_file():
            dict_num += 1
            print(f'â˜‘ï¸  å·²åŠ è½½ç¬¬ {dict_num} ä»½ç è¡¨ Â» {filepath.name}')
            
            with open(filepath, 'r', encoding='utf-8') as f:
                for line in f:
                    if not line or not is_chinese_char(line[0]):
                        continue
                        
                    parts = tab_split_re.split(line.strip())
                    if len(parts) < 2:
                        continue
                        
                    word, code = parts[0], parts[1]
                    weight = parts[2] if len(parts) >= 3 else '0'
                    word_len = len(word)
                    
                    try:
                        if word not in res_dict or code not in res_dict_code[word]:
                            res_dict[word] = {code}
                            res_dict_code[word].add(code)
                            
                            if word_len not in word_len_groups:
                                word_len_groups[word_len] = []
                            word_len_groups[word_len].append(f"{word}\t{code}\t{weight}\n")
                    except KeyError:
                        continue
    
    print('\nğŸ”œ  --- æ­£åœ¨åˆå¹¶å¤„ç†è¯åº“æ–‡ä»¶ ---')
    
    # æŒ‰è¯é•¿æ’åºå¹¶æ”¶é›†ç»“æœ
    output_lines = []
    line_count_sum = 0
    for word_len in sorted(word_len_groups.keys()):
        group_lines = word_len_groups[word_len]
        output_lines.extend(group_lines)
        line_count_sum += len(group_lines)
        print(f'â˜‘ï¸  å·²åˆå¹¶å¤„ç†ç”Ÿæˆ {word_len} å­—è¯è¯­ï¼Œå…±è®¡ {len(group_lines)} è¡Œ')
    
    print(f'âœ… Â» å…±ç”Ÿæˆ {line_count_sum} è¡Œæ•°æ®')
    
    # å†™å…¥è¾“å‡ºæ–‡ä»¶
    out_file.parent.mkdir(parents=True, exist_ok=True)
    if out_file.exists():
        out_file.unlink()
        
    with open(out_file, 'w', encoding='utf-8') as o:
        o.write(get_header_ext(out_file.name))
        o.writelines(output_lines)


def get_md5(text: str) -> str:
    """è®¡ç®—å­—ç¬¦ä¸²çš„ MD5 å“ˆå¸Œå€¼"""
    md5 = hashlib.md5()  # åˆ›å»º MD5 å¯¹è±¡
    md5.update(text.encode('utf-8'))  # ä¼ å…¥å­—èŠ‚æ•°æ®ï¼ˆå¿…é¡» encodeï¼‰
    return md5.hexdigest()  # è¿”å› 32 ä½ 16 è¿›åˆ¶å­—ç¬¦ä¸²

@timer
def sort_dict(src_dir, out_dir, dict_start):
    """åˆ†ç»„æ’åºå¤„ç†ç”¨æˆ·è¯å…¸"""
    res_dict = {}
    lines_total = []

    # åŠ è½½æ‰€æœ‰è¯å…¸æ–‡ä»¶
    for file_path in src_dir.iterdir():
        if file_path.is_file() and file_path.name.startswith(dict_start):
            with open(file_path, 'r', encoding='utf-8') as f:
                lines_total.extend(f.readlines())

    # ä¿ç•™åŸæœ‰è¯å…¸è¡¨å¤´
    header_str = ''
    is_header_end = False
    for line in lines_total:
        if line.startswith('.'):
            is_header_end = True
        if not is_chinese_char(line[0]) and not is_header_end:
            header_str += line 


    # å»é‡å¹¶å¤„ç†è¯æ¡
    for line in set(lines_total):
        if is_chinese_char(line[0]):
            word, code, weight = line.strip().split('\t')
            weight = int(weight)
            
            # å”¯ä¸€åŒ–
            if word not in res_dict:
                res_dict[word + get_md5(line)] = f'{code}\t{weight}'


    # å¤šçº§åˆ†ç»„æ’åºï¼ˆè¯é•¿â†’ç¼–ç é•¿åº¦â†’ç¼–ç â†’æ±‰å­—ï¼‰
    with open(out_dir / f'{dict_start}.dict.yaml', 'w', encoding='utf-8') as o:
        o.write(header_str)
        # o.write(get_header_sort(out_file))
        o.write('...\n')
        
        # ç¬¬ä¸€çº§ï¼šæŒ‰è¯é•¿åˆ†ç»„
        word_len_dict = defaultdict(list)
        for word, value in res_dict.items():
            word_len_dict[len(word)].append((word, value))

        # å¤„ç†æ¯ç»„è¯é•¿
        for word_len in sorted(word_len_dict.keys()):
            # ç¬¬äºŒçº§ï¼šæŒ‰ç¼–ç é•¿åº¦åˆ†ç»„
            code_len_dict = defaultdict(list)
            for word, value in word_len_dict[word_len]:
                code = value.split('\t')[0]
                code_len_dict[len(code)].append((word, code, value))

            # æŒ‰ç¼–ç é•¿åº¦å¤„ç†
            for code_len in sorted(code_len_dict.keys()):
                # å…³é”®ä¿®æ”¹ï¼šå½“ç¼–ç ç›¸åŒæ—¶ï¼ŒæŒ‰æ±‰å­—unicodeæ’åº
                group = sorted(code_len_dict[code_len], 
                             key=lambda x: (x[1], x[0]))  # å…ˆæŒ‰ç¼–ç æ’åºï¼Œå†æŒ‰æ±‰å­—æ’åº
                for word, _, value in group:
                    o.write(f'{word[:-32]}\t{value}\n')
            print(f'â˜‘ï¸  å·²æ’åºå¤„ç†ç”Ÿæˆ {word_len - 32} å­—è¯è¯­')
        print('âœ… Â» å·²æ’åºç”Ÿæˆç”¨æˆ·è¯å…¸ %s' % (out_dir / f'{dict_start}.dict.yaml'))


def get_remote_mtime(url):
    '''
    è·å–è¿œç¨‹èµ„æºæ›´æ–°æ—¥æœŸ
    '''
    with urllib.request.urlopen(url) as response:
        last_modified = response.getheader('Last-Modified')
        if last_modified:
            # è½¬æ¢GMTæ—¶é—´å­—ç¬¦ä¸²ä¸ºæ—¶é—´æˆ³ï¼ˆéœ€å¤„ç†æ—¶åŒºè¯·è‡ªè¡Œè°ƒæ•´ï¼‰
            gmt_time = datetime.strptime(last_modified, '%a, %d %b %Y %H:%M:%S GMT')
            # æ·»åŠ UTCæ—¶åŒºæ ‡è®°
            utc_time = gmt_time.replace(tzinfo=timezone.utc)
            # è½¬æ¢ä¸ºåŒ—äº¬æ—¶é—´ï¼ˆä¸œå…«åŒºï¼‰
            beijing_time = utc_time.astimezone(timezone(timedelta(hours=8)))
            
            return beijing_time.strftime('%Y-%m-%d %H:%M:%S')
    return None

def fetch_url_file(url, out_dir, is_download_gram = False):
    '''
    è·å–è¿œç¨‹æ–‡ä»¶  
    url - è¿œç¨‹èµ„æºåœ°å€  
    out_dir - å­˜æ”¾ç›®å½•  
    is_download_gram - æ˜¯å¦ä¸‹è½½å¤§æ¨¡å‹  
    '''
    default_url = 'https://github.com/amzxyz/rime_wanxiang_pro/releases/download/dict-nightly/9-cn_dicts.zip'
    url = url or default_url

    filename = os.path.basename(url)
    filename = 'cn_dicts.zip' if not is_download_gram else 'wanxiang-lts-zh-hans.gram'
    out_dir.mkdir(parents=True, exist_ok=True)

    try:
        with urllib.request.urlopen(url) as response:
            total_size = int(response.headers.get('content-length', 0))
            downloaded = 0
            chunk_size = 8192  # 8KB

            with open(out_dir / filename, 'wb') as f:
                while True:
                    chunk = response.read(chunk_size)
                    if not chunk:
                        break
                    f.write(chunk)
                    downloaded += len(chunk)
                    format_progress_bar(downloaded, total_size)
        print(f"\nâœ… Â» ä¸‹è½½å®Œæˆ {out_dir}")
    except Exception as e:
        print(f"\nä¸‹è½½å¤±è´¥ï¼š{e}")

@timer
def download_dict(url_dict, out_url_directory, is_download_gram = False):
    """
    url_dict - å¦‚ https://github.com/amzxyz/rime_wanxiang/releases/download/dict-nightly/cn_dicts.zip
    out_url_directory - å¦‚ C:\\Users\\jack\\AppData\\Roaming\\.temp_rime\\rime_url
    is_download_gram - False é»˜è®¤ä¸ä¸‹è½½å¤§æ¨¡å‹
    """
    # ç›´æ¥ä¸‹è½½ä»“åº“è¯å…¸æ–‡ä»¶
    url_dict = url_dict or url_dict_rime_wanxiang                                         # è¿œç¨‹èµ„æºåœ°å€
    out_url_directory = out_url_directory or (proj_dir / work_dir / 'rime_url').resolve() # é¢„è®¾ä¸‹è½½ç›®å½•
    out_file = 'cn_dicts.zip'

    if is_download_gram:
        url_dict = url_dict or url_gram
        out_url_directory = out_url_directory or proj_dir
        out_file = 'wanxiang-lts-zh-hans.gram'

    print(f'ğŸ”œ  è¿œç¨‹èµ„æºï¼š {url_dict}')
    print(f'ğŸ”œ  ç›®æ ‡è·¯å¾„ï¼š {out_url_directory}')
    
    # modified time
    # current_datetime = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    # print(f'å½“å‰æ—¶é—´ï¼š{current_datetime}')
    cur_remote_file_mtime = get_remote_mtime(url_dict)
    print(f'è¿œç¨‹æ–‡ä»¶æ›´æ–°æ—¶é—´ï¼š{cur_remote_file_mtime}')

    if (out_url_directory / out_file).exists():
        pre_mtime = datetime.fromtimestamp(os.path.getmtime((out_url_directory / out_file))).strftime('%Y-%m-%d %H:%M:%S')
        # æ–‡ä»¶ä¸Šæ¬¡ä¸‹è½½æ—¶é—´ > è¿œç¨‹æ–‡ä»¶æ›´æ–°æ—¶é—´ â­ æ— éœ€ä¸‹è½½
        print(f'æ–‡ä»¶ä¸Šæ¬¡ä¸‹è½½æ—¶é—´ï¼š{pre_mtime}')
        delta = datetime.strptime(pre_mtime, "%Y-%m-%d %H:%M:%S").timestamp() - datetime.strptime(cur_remote_file_mtime, "%Y-%m-%d %H:%M:%S").timestamp()
        # print(int(int(delta) / 60 / 60 / 24 ))
        if delta > 0:
            print('âœ…  Â» æ— éœ€ä¸‹è½½ Â¦ ä»“åº“æ²¡æœ‰æ–°çš„æäº¤')
            return False
        else:
            fetch_url_file(url_dict, out_url_directory, is_download_gram)
    else:
        fetch_url_file(url_dict, out_url_directory)
        # è§£å‹æ•´ä¸ªZIPæ–‡ä»¶åˆ°æŒ‡å®šç›®å½•
        if not is_download_gram:
            with zipfile.ZipFile((out_url_directory / out_file), 'r') as zip_ref:
                zip_ref.extractall(out_url_directory)


def exec(proj_dir, work_dir, repository_url):
    exec_success = True

    # â‘  åŒæ­¥ä»“åº“
    repository_url = repository_url or "https://github.com/amzxyz/rime_wanxiang.git"
    repository_name = repository_url.split('/')[-1][:-4] # å¦‚ rime_wanxiang
    local_directory = (proj_dir / work_dir / repository_name).resolve()
    out_dict = f'cn_dicts_{repository_name}'

    if not is_local:
        print('ğŸ”œ  === å¼€å§‹è·å–æœ€æ–°è¯åº“æ–‡ä»¶ ===')
        if is_clone_repo:
            exec_success = sync_repository(repository_url, local_directory)
            if not exec_success:
                return False;
        else:
            # ç›´æ¥ä¸‹è½½ä»“åº“è¯å…¸æ–‡ä»¶
            is_pinyin = code_type.startswith("1")
            url_dict = url_dict_rime_wanxiang
            out_url_directory = (proj_dir / work_dir / 'rime_url').resolve()

            if is_pinyin:
                url_dict = url_dict_rime_wanxiang_pro
                out_url_directory = (proj_dir / work_dir / 'rime_url_pro').resolve()

            download_dict(url_dict, out_url_directory)
            exec_success = ask_yes_no("ğŸ””  æ˜¯å¦ç»§ç»­æ‰§è¡Œè½¬æ¢æ“ä½œ")
            if not exec_success:
                return False;
        
            # æ›´æ–°å·¥ä½œæ–‡ä»¶ç›®å½• 
            repository_name = 'rime_url'
            out_dict = 'cn_dicts_rime_url'

            if is_pinyin:
                repository_name = 'rime_url_pro'
                out_dict = 'cn_dicts_rime_url_pro'

            print(f'â˜‘ï¸  å·²åŠ è½½è¯å…¸ {out_url_directory}/cn_dicts \n')                

    else:
        print('ğŸ”œ  === å¼€å§‹è½¬æ¢æœ¬åœ°è¯åº“æ–‡ä»¶ ===')
        if not local_directory.exists():
            print(f'''
ğŸš«  è¯·æ£€æŸ¥ .temp_rime/{repository_name}/cn_dicts æ˜¯å¦å­˜åœ¨
--- Tips ---------------------------------------------------------------------
# Â¹ æœ¬åœ°è¯åº“æ–‡ä»¶å¤¹ä¸º .temp_rime/rime_local/cn_dicts
# Â² å…¶ä¸­ .temp_rime ä¸ scripts çˆ¶çº§ç›®å½•åŒçº§
------------------------------------------------------------------------------
            ''')
            return False
        else:
            print(f'â˜‘ï¸  å·²åŠ è½½è¯å…¸ {local_directory}/cn_dicts \n')

    # â‘¡ è½¬æ¢æ‹¼éŸ³è¯åº“ä¸ºäº”ç¬”è¯åº“
    src_dir = proj_dir / work_dir / repository_name / 'cn_dicts'
    out_dir = proj_dir / work_dir / out_dict
    # å·²å­˜åœ¨ï¼Œå…ˆåˆ é™¤ï¼Œå†è½¬æ¢
    if out_dir.exists():
        shutil.rmtree(out_dir)
    print('\nğŸ”œ  === å¼€å§‹åŒæ­¥è½¬æ¢è¯åº“æ–‡ä»¶ ===')
    convert(src_dir, out_dir, '.dict.yaml')

    # åˆ†åŒ…æ“ä½œï¼Œä»¥å‡å°æ¨é€ä¹‹åä»“åº“å¿«ç…§ä½“ç§¯
    if not is_merge:
        dist_dir = proj_dir / 'cn_dicts'
        if dist_dir.exists():
            shutil.rmtree(dist_dir)
        shutil.copytree(out_dir, dist_dir)
        return

    # â‘¢ è¿‡æ»¤åˆå¹¶äº”ç¬”ç è¡¨
    out_file_name = ''
    if code_type.startswith("1"):
        out_file_name = 'pinyin.dict.yaml'
    elif code_type.startswith("20"):
        out_file_name = 'wubi86_ext.dict.yaml'
    elif code_type.startswith("21"):
        out_file_name = 'wubi86_zj.dict.yaml'
    elif code_type.startswith("30"):
        out_file_name = 'tiger_ext.dict.yaml'
    elif code_type.startswith("31"):
        out_file_name = 'tiger_zj.dict.yaml'

    src_dir = proj_dir / work_dir / out_dict
    out_file = proj_dir / work_dir / out_file_name
    print('\nğŸ”œ  === å¼€å§‹åˆå¹¶å¤„ç†è¯åº“æ–‡ä»¶ ===')
    filter_8105(src_dir, out_file)
    
    # â‘£ é‡æ–°æ’åº
    src_dir = proj_dir /  work_dir
    out_dir = proj_dir / 'dicts'
    dict_start = ''
    if code_type.startswith("1"):
        dict_start = 'pinyin'
    elif code_type.startswith("20"):
        dict_start = 'wubi86_ext'
    elif code_type.startswith("21"):
        dict_start = 'wubi86_zj'
    elif code_type.startswith("30"):
        dict_start = 'tiger_ext'
    elif code_type.startswith("31"):
        dict_start = 'tiger_zj'

    # è‹¥ä¸å­˜åœ¨ï¼Œåˆ›å»º
    if not out_dir.exists():
        out_dir.mkdir(parents=True, exist_ok=True)
    print('\nğŸ”œ  === å¼€å§‹æ’åºå¤„ç†è¯åº“æ–‡ä»¶ ===')
    # æ’åºå¤„ç†è‡³ç”¨æˆ·è¯å…¸
    sort_dict(src_dir, out_dir, dict_start)


    is_download_gram = ask_yes_no("ğŸ””  æ˜¯å¦ç»§ç»­ä¸‹è½½è¯­è¨€å¤§æ¨¡å‹")
    if not is_download_gram:
        return False;
    download_dict(url_gram, proj_dir, is_download_gram)

if __name__ == "__main__":
    proj_dir = Path(__file__).resolve().parent.parent
    work_dir = "../.temp_rime"

    # === å¯é…ç½®é¡¹ ===
    # â‘  --- ç¼–ç ç±»å‹ ---
    # !!! è½¬æ¢æ‹¼éŸ³ç¼–ç éœ€è¦ä¸‡è±¡æ‹¼éŸ³Proä¸ºåº•åº§ï¼Œå³ repository_url = "https://github.com/amzxyz/rime_wanxiang_pro.git"
    # !!! äº”ç¬”ã€è™ç æ”¯æŒä½¿ç”¨å…¶ä»–ä»“åº“ï¼Œå¦‚é›¾å‡‡ã€ç™½éœœã€ä¸‡è±¡æ‹¼éŸ³åŸºç¡€ç‰ˆç­‰
    # ç›®æ ‡è½¬ç ç±»å‹ï¼š
    # Â¹ æ‹¼éŸ³ï¼šÂ¹1 moqi å¢¨å¥‡, Â¹2 flypy é¹¤å½¢, Â¹3 zrm è‡ªç„¶ç , Â¹4 jdh ç®€å•é¹¤, Â¹5 cj ä»“é¢‰,
    #         Â¹6 tiger è™ç é¦–æœ«, Â¹7 wubi äº”ç¬”å‰äºŒ, Â¹8 hanxin æ±‰å¿ƒï¼ŒÂ¹0 çº¯æ‹¼éŸ³
    # 
    # Â² äº”ç¬”ï¼šÂ²1 äº”ç¬”æ•´å¥ï¼ŒÂ²0 äº”ç¬”å¸¸è§„
    # Â³ è™ç ï¼šÂ³1 è™ç æ•´å¥ï¼ŒÂ³0 è™ç å¸¸è§„ 
    code_type = sys.argv[1] if len(sys.argv) > 1 else ''
    code_dict = { 
        '10': 'çº¯æ‹¼éŸ³', '11': 'å¢¨å¥‡', '12': 'é¹¤å½¢', '13': 'è‡ªç„¶ç ', '14': 'ç®€å•é¹¤', '15': 'ä»“é¢‰', '16': 'è™ç é¦–æœ«', '17': 'äº”ç¬”å‰äºŒ', '18': 'æ±‰å¿ƒ',  
        '20': 'äº”ç¬”å¸¸è§„','21': 'äº”ç¬”æ•´å¥',
        '30': 'è™ç å¸¸è§„','31': 'è™ç æ•´å¥' 
    }

    if code_type not in code_dict:
        print(f'''
ğŸ””  è¯·è¾“å…¥æ­£ç¡®çš„è¯å…¸æ ‡è¯†ç :
------------------------------------------------------------------------------
# ç›®æ ‡è½¬ç ç±»å‹ï¼š
# Â¹ æ‹¼éŸ³ï¼šÂ¹1 moqi å¢¨å¥‡, Â¹2 flypy é¹¤å½¢, Â¹3 zrm è‡ªç„¶ç , Â¹4 jdh ç®€å•é¹¤, Â¹5 cj ä»“é¢‰,
#         Â¹6 tiger è™ç é¦–æœ«, Â¹7 wubi äº”ç¬”å‰äºŒ, Â¹8 hanxin æ±‰å¿ƒï¼ŒÂ¹0 çº¯æ‹¼éŸ³
# 
# Â² äº”ç¬”ï¼šÂ²1 äº”ç¬”æ•´å¥ï¼ŒÂ²0 äº”ç¬”å¸¸è§„
# Â³ è™ç ï¼šÂ³1 è™ç æ•´å¥ï¼ŒÂ³0 è™ç å¸¸è§„ 

å¦‚ï¼š16 â­ æ‹¼éŸ³+è™ç é¦–æœ«ï¼›20 â­ äº”ç¬”å¸¸è§„ï¼›31 â­ è™ç æ•´å¥
------------------------------------------------------------------------------
        ''')
        code_type = input(f"ğŸ””  é»˜è®¤ã€Œ è™ç æ•´å¥ ã€? (31): ").strip().lower() or "31"
        # print(f'ğŸ”œ  {code_type}   â­ {code_dict[code_type]}\n')
    print(f'----------- {code_dict[code_type]} -----------')

    # â‘¡ --- å­—é›†è¿‡æ»¤ ---
    # æ˜¯å¦å¼€å¯ 8105 é€šè§„å­—å­—ç¬¦èŒƒå›´è¿‡æ»¤ã€Œ ğŸ”¥ å¼ºçƒˆæ¨èå¼€å¯ ã€
    # è¯¥è®¾ç½®é¡¹ä»…ä¾›æœ‰æ‰©å±•å­—ç¬¦é›†éœ€æ±‚çš„ç”¨æˆ·
    # æ‹¼éŸ³ã€è™ç å·²æä¾›å¤§å­—é›†æ˜ å°„ï¼Œäº”ç¬”é»˜è®¤æä¾› 8105 é€šè§„å­—æ˜ å°„
    # !!! å†æ¬¡å¼ºçƒˆæ¨èå¼€å¯
    is_filter_8105 = True

    # â‘¢ --- åˆ†åŒ…å½’å¹¶ ---
    # åˆ†åŒ…è¿˜æ˜¯å½’å¹¶ã€Œ åˆå¹¶åå¯æé«˜ Rime é‡æ–°éƒ¨ç½²é€Ÿåº¦ ã€
    # - å½’å¹¶ True ï¼ˆdicts/pinyin.dict.yamlã€dicts/*_ext.dict.yamlã€dicts/*_zj.dict.yamlï¼‰
    # - åˆ†åŒ… False ï¼ˆcn_dicts/*ï¼‰
    is_merge = True

    # â‘£ --- è¯é•¿é™åˆ¶ ---
    # æ˜¯å¦é™åˆ¶è¯åº“æœ€å¤§è¯é•¿ï¼Œè‹¥ä¸º 0 ï¼Œåˆ™ä¸é™åˆ¶
    word_length_limit = 0

    # â‘¤ --- ä»“åº“æŒ‡å®š ---
    # å¾…è½¬æ¢çš„è¯å…¸ä»“åº“ - ç½‘ç»œä»“åº“ 0 / æœ¬åœ°ä»“åº“ 1
    # â° ç½‘ç»œä»“åº“
    # ----------
    # !!! è½¬æ¢æ‹¼éŸ³ç¼–ç éœ€è¦ä¸‡è±¡æ‹¼éŸ³Proä¸ºåº•åº§
    rime_wanxiang_pro = "https://github.com/amzxyz/rime_wanxiang_pro.git"
    rime_wanxiang = "https://github.com/amzxyz/rime_wanxiang.git"
    repository_url = rime_wanxiang_pro if code_type.startswith("1") else rime_wanxiang
    # repository_url = "https://github.com/gaboolic/rime-frost.git"
    # repository_url = "https://github.com/iDvel/rime-ice.git"
    # print(repository_url)
    # 
    # å…‹éš†ä»“åº“ â† 1  0 â†’ ç›´æ¥ä¸‹è½½å­—å…¸å‹ç¼©åŒ…æˆ–æ¨¡å‹
    # â°â° ç›´æ¥ä¸‹è½½å­—å…¸å‹ç¼©åŒ…æˆ–æ¨¡å‹
    is_clone_repo = bool(int(sys.argv[3] if len(sys.argv) > 3 else 0))
    # is_clone_repo ä¸º 0 æ—¶
    # ä¸ºäº†ä¸å¢åŠ è„šæœ¬å¤æ‚æ€§ï¼Œæˆ‘ä»¬å›ºå®šæœ¬åœ°è¯åº“æ–‡ä»¶å¤¹ä¸ºï¼š
    # - æ‹¼éŸ³ + è¾…åŠ©ç  .temp_rime/rime_url_pro/cn_dicts
    # - å½¢ç æ•´å¥      .temp_rime/rime_url/cn_dicts
    # å…¶ä¸­ .temp_rime ä¸ scripts çˆ¶çº§ç›®å½•åŒçº§
    # ----------
    # url_dict_rime_ice = "https://github.com/iDvel/rime-ice/releases/download/2025.04.06/en_dicts.zip"
    # url_dict_rime_ice = "https://github.com/iDvel/rime-ice/releases/download/2025.04.06/cn_dicts.zip"
    url_dict_rime_wanxiang_pro = "https://github.com/amzxyz/rime_wanxiang_pro/releases/download/dict-nightly/9-cn_dicts.zip"
    url_dict_rime_wanxiang = "https://github.com/amzxyz/rime_wanxiang/releases/download/dict-nightly/cn_dicts.zip"
    # 
    # Â¹ æœ¬åœ°ä»“åº“
    # ----------
    # ä¸ºäº†ä¸å¢åŠ è„šæœ¬å¤æ‚æ€§ï¼Œæˆ‘ä»¬å›ºå®šæœ¬åœ°è¯åº“æ–‡ä»¶å¤¹ä¸º .temp_rime/rime_local/cn_dicts
    # å…¶ä¸­ .temp_rime ä¸ scripts çˆ¶çº§ç›®å½•åŒçº§
    is_local = bool(int(sys.argv[2] if len(sys.argv) > 2 else 0))
    # [ rime_local/cn_dicts ]
    # ï¼ä»“åº“éœ€è¦é‡å‘½åä¸º rime_local ï¼Œå­—å…¸ç½®äº cn_dicts ä¸­
    repository_url = 'rime_local.git' if is_local else repository_url
    # 
    # æ˜¯å¦éœ€è¦ä¸‹è½½è¯­è¨€å¤§æ¨¡å‹
    is_download_gram = bool(int(sys.argv[4] if len(sys.argv) > 4 else 0))
    url_gram = 'https://github.com/amzxyz/RIME-LMDG/releases/download/LTS/wanxiang-lts-zh-hans.gram'

    # å¼€å§‹æ‰§è¡Œ
    exec(proj_dir, work_dir, repository_url)