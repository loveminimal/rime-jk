# æ’åºç°æœ‰æ ‡å‡†è¯åº“
# created by Jack Liu <https://aituyaa.com>
# 
import hashlib
from pathlib import Path
from collections import defaultdict
from header import get_header_sort
from timer import timer
from wubi86_8105_map import wubi86_8105_map
from three_level_8105 import first_level, second_level, third_level


def is_chinese_char(char: str) -> bool:
    """
    åˆ¤æ–­å­—ç¬¦æ˜¯å¦å±äºã€Šé€šç”¨è§„èŒƒæ±‰å­—è¡¨ã€‹8105å­—èŒƒå›´å†…çš„æ±‰å­—ã€‚
    ä½¿ç”¨ Unicode åŒºé—´åˆ—è¡¨ä¼˜åŒ–åˆ¤æ–­ã€‚
    """
    if len(char) != 1:
        return False
    
    code = ord(char)
    # æ‰€æœ‰ CJK æ±‰å­— Unicode åŒºé—´ï¼ˆåŸºæœ¬åŒº + æ‰©å±•A-Gï¼‰
    cjk_ranges = [
        (0x4E00, 0x9FFF),    # åŸºæœ¬åŒº
        (0x3400, 0x4DBF),    # æ‰©å±•A
        (0x20000, 0x2A6DF),  # æ‰©å±•B
        (0x2A700, 0x2B73F),  # æ‰©å±•C
        (0x2B740, 0x2B81F),  # æ‰©å±•D
        (0x2B820, 0x2CEAF),  # æ‰©å±•E
        (0x2CEB0, 0x2EBEF),  # æ‰©å±•F
        (0x30000, 0x3134F),  # æ‰©å±•G
    ]
    
    return any(start <= code <= end for start, end in cjk_ranges)

def get_md5(text: str) -> str:
    """è®¡ç®—å­—ç¬¦ä¸²çš„ MD5 å“ˆå¸Œå€¼"""
    md5 = hashlib.md5()  # åˆ›å»º MD5 å¯¹è±¡
    md5.update(text.encode('utf-8'))  # ä¼ å…¥å­—èŠ‚æ•°æ®ï¼ˆå¿…é¡» encodeï¼‰
    return md5.hexdigest()  # è¿”å› 32 ä½ 16 è¿›åˆ¶å­—ç¬¦ä¸²

def get_wubi_code(word: str) -> str:
    """å°†æ±‰å­—è½¬æ¢ä¸ºäº”ç¬”ç¼–ç """
    if len(word) == 1:
        return f'{wubi86_8105_map[word]}'
    elif len(word) == 2:
        return f'{wubi86_8105_map[word[0]][:2]}{wubi86_8105_map[word[1]][:2]}'
    elif len(word) == 3:
        return f'{wubi86_8105_map[word[0]][0]}{wubi86_8105_map[word[1]][0]}{wubi86_8105_map[word[2]][:2]}'
    elif len(word) >= 4:
        return f'{wubi86_8105_map[word[0]][0]}{wubi86_8105_map[word[1]][0]}{wubi86_8105_map[word[2]][0]}{wubi86_8105_map[word[len(word) - 1]][0]}'


@timer
def sort_dict(src_dir, out_dir):
    count = 0
    line_dict = set()
    res = ''
    res_dict = {}
    res_dict_weight = defaultdict(set)
    lines_total = []

    # åŠ è½½æ‰€æœ‰è¯å…¸æ–‡ä»¶
    for file_path in src_dir.iterdir():
        if file_path.is_file() and file_path.name.startswith(dict_start):
            with open(file_path, 'r', encoding='utf-8') as f:
                lines_total.extend(f.readlines())

    # ä¿ç•™åŸæœ‰è¯å…¸è¡¨å¤´
    header_str = ''
    is_header_end = False
    for line in lines_total:
        if line.startswith('.'):
            is_header_end = True
        if not is_chinese_char(line[0]) and not is_header_end:
            header_str += line 

    res_dict_temp = set()   # å­˜å‚¨å­—å…¸ä¸­çš„å•å­—
    res_dict_temp1 = set()  # å­˜å‚¨å­—å…¸ä¸­ç¼ºå¤±çš„ 8105 å•å­—
    # å»é‡å¹¶å¤„ç†è¯æ¡
    for line in set(lines_total) if is_sort else lines_total:
        if (is_chinese_char(line[0])):
            if line not in line_dict:
                line_dict.add(line)
            else:
                count += 1
                # print(f'{count} - {line}')
                continue

            # word, code, weight = line.strip().split('\t')
            _arr = line.strip().split('\t')
            word = _arr[0]
            code = _arr[1]
            weight = int(_arr[2]) if len(_arr) > 2 else 0
            # if word not in res_dict or weight > max(res_dict_weight[word]):
            #     res_dict[word] = f'{code}\t{weight}'
            #     res_dict_weight[word].add(weight)
            
            # æŒ‰ç è¡¨åˆ†çº§æ·»åŠ ç›¸åº”æƒé‡ï¼Œä¸€çº§å­—-3 äºŒçº§å­—-2 ä¸‰çº§å­—-1 è¯è¯­-2
            # if len(word) == 1:
            #     if word in first_level:
            #         weight = 3
            #     elif word in second_level:
            #         weight = 2
            #     elif word in third_level:
            #         weight = 1
            # else:
            #     weight = 2
            if(len(word) == 1):
                res_dict_temp.add(word)
            # print(len(res_dict_temp))


            # æ·»åŠ ç›¸åº”æƒé‡ï¼Œä¸€çº§å­—-100 äºŒçº§å­—-10 ä¸‰çº§å­—-1 è¯è¯­-3ã€2ï¼Œä¸‰çº§å­—æ²¡æœ‰ç»„è¯
            if all((char in first_level) for char in word):
                weight = 100000
            elif any((char in second_level) for char in word):
                weight = 1000
            elif any((char in third_level) for char in word):
                weight = 10
            
            # 8105 è¿‡æ»¤å™¨å¼€å…³ - is_filter_8105
            if is_filter_8105 and any((char not in wubi86_8105_map and char not in white_list) for char in word):
                continue
            
            # å”¯ä¸€åŒ–
            if word not in res_dict:
                res_dict[word + get_md5(line)] = f'{code}\t{weight}'
                # res_dict_weight[word].add(weight)
                if not is_sort:
                    # æ­¤å¤„å°†ç‹ç å¤§ä¸€ç»Ÿç‰ˆæœ¬çš„æ¢å¤è‡³ 4.5 ç‰ˆæœ¬ç¼–ç 
                    code = get_wubi_code(word) if len(code) > 3 else code
                    res += f'{word}\t{code}\t{weight}\n'

    print(f'âœ…  Â» å·²è¿‡æ»¤ {count} è¡Œé‡å¤è¯æ¡')

    # è¡¥å……è¯åº“ä¸­å¯èƒ½ç¼ºå¤±çš„é€šè§„å­— 8105 å•å­—
    count1 = 0
    for word1 in wubi86_8105_map:
        if word1 not in res_dict_temp:
            res_dict_temp1.add(word1)
            count1 += 1
            line1 = f'{word1}\t{wubi86_8105_map[word1]}\t1'
            # print(f'{count1} - {line1}')
            res_dict[word1 + get_md5(line1)] = f'{wubi86_8105_map[word1]}\t1'

            if not is_sort:
                res += f'{word1}\t{wubi86_8105_map[word1]}\t1\n'

    # å¤šçº§åˆ†ç»„æ’åºï¼ˆè¯é•¿â†’ç¼–ç é•¿åº¦â†’ç¼–ç â†’æ±‰å­—ï¼‰
    with open(out_dir / out_file, 'w', encoding='utf-8') as o:
        o.write(header_str)
        # o.write(get_header_sort(out_file))
        o.write('...\n')

        if not is_sort:
            o.write(res)
            print('âœ…  Â» å·²åˆå¹¶ç”Ÿæˆç”¨æˆ·è¯å…¸ %s' % (out_dir / out_file))
            return
        
        # ç¬¬ä¸€çº§ï¼šæŒ‰è¯é•¿åˆ†ç»„
        word_len_dict = defaultdict(list)
        for word, value in res_dict.items():
            word_len_dict[len(word)].append((word, value))

        # å¤„ç†æ¯ç»„è¯é•¿
        for word_len in sorted(word_len_dict.keys()):
            # ç¬¬äºŒçº§ï¼šæŒ‰ç¼–ç é•¿åº¦åˆ†ç»„
            code_len_dict = defaultdict(list)
            for word, value in word_len_dict[word_len]:
                code = value.split('\t')[0]
                code_len_dict[len(code)].append((word, code, value))

            # æŒ‰ç¼–ç é•¿åº¦å¤„ç†
            for code_len in sorted(code_len_dict.keys()):
                # å…³é”®ä¿®æ”¹ï¼šå½“ç¼–ç ç›¸åŒæ—¶ï¼ŒæŒ‰æ±‰å­—unicodeæ’åº
                group = sorted(code_len_dict[code_len], 
                             key=lambda x: (x[1], x[0]))  # å…ˆæŒ‰ç¼–ç æ’åºï¼Œå†æŒ‰æ±‰å­—æ’åº
                            #  key=lambda x: (x[0], x[1]))  # å…ˆæŒ‰æ±‰å­—æ’åºï¼Œå†æŒ‰ç¼–ç æ’åº
                for word, _, value in group:
                    o.write(f'{word[:-32]}\t{value}\n')
            print(f'â˜‘ï¸  å·²åˆå¹¶å¤„ç†ç”Ÿæˆ {word_len - 32} å­—è¯è¯­')
        print('âœ…  Â» å·²åˆå¹¶ç”Ÿæˆç”¨æˆ·è¯å…¸ %s' % (out_dir / out_file))


if __name__ == '__main__':
    current_dir = Path.cwd()

    # æ˜¯å¦å¼€å¯ 8105 é€šè§„å­—å­—ç¬¦èŒƒå›´è¿‡æ»¤
    is_filter_8105 = True
    white_list = ['ï¼Œ']
    # æ˜¯å¦æ”¹å˜åŸè¯å…¸é¡ºåºï¼ˆç”¨äºä¸æƒ³æ”¹å˜è¯å…¸é¡ºåºçš„æƒ…å†µï¼‰
    is_sort = False

    src_dir = Path('C:\\Users\\jack\\AppData\\Roaming\\Rime\\dicts')
    out_dir = Path('C:\\Users\\jack\\AppData\\Roaming\\Rime\\dicts\\out')
    dict_start = 'wubi86.dict.yaml'

    if not out_dir.exists():
        out_dir.mkdir(parents=True, exist_ok=True)

    # out_file = f'{dict_start}.sorted.dict.yaml'
    # out_file = f'{dict_start}.dict.yaml'
    out_file = dict_start

    print('ğŸ”œ  === å¼€å§‹åŒæ­¥è½¬æ¢è¯åº“æ–‡ä»¶ ===')
    # åˆå¹¶è‡³ç”¨æˆ·æ–‡ä»¶
    sort_dict(src_dir, out_dir)

