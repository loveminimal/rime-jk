import os
import re
import subprocess
import hashlib
from pathlib import Path
from timer import timer
from wubi86_8105_map import wubi86_8105_map
from header import get_header_zj
from collections import defaultdict


def run_git_command(command, cwd=None):
    """æ‰§è¡Œgitå‘½ä»¤å¹¶è¿”å›æ˜¯å¦æˆåŠŸ"""
    try:
        subprocess.run(
            ["git"] + command,
            cwd=cwd,
            check=True,
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
            text=True
        )
        return True
    except subprocess.CalledProcessError:
        return False


def sync_repository(repo_url, local_path):
    """åŒæ­¥Gitä»“åº“ï¼ˆå…‹éš†æ—¶åªè·å–æœ€æ–°ç‰ˆæœ¬ï¼‰"""
    git_dir = local_path / ".git"
    
    if git_dir.exists():
        print(f"ä»“åº“å·²å­˜åœ¨äº {local_path}")
        print(f"ğŸ”œ  æ­£åœ¨æ‹‰å–æœ€æ–°æ›´æ–°...")
        if run_git_command(["pull"], cwd=local_path):
            print("âœ…  Â» æ‹‰å–æ›´æ–°æˆåŠŸ")
        else:
            print("ğŸš«  Â» æ‹‰å–æ›´æ–°å¤±è´¥")
    else:
        print(f"æœ¬åœ°ä»“åº“ä¸å­˜åœ¨")
        print(f"ğŸ”œ  æ­£åœ¨æµ…å…‹éš† {repo_url}...")
        local_path.parent.mkdir(parents=True, exist_ok=True)
        
        if run_git_command(["clone", "--depth=1", repo_url, str(local_path)]):
            print(f"âœ…  Â» ä»“åº“å·²æµ…å…‹éš†åˆ° {local_path}")
        else:
            print("ğŸš«  Â» å…‹éš†ä»“åº“å¤±è´¥")


def get_wubi_code(word: str) -> str:
    """å°†æ±‰å­—è½¬æ¢ä¸ºäº”ç¬”ç¼–ç """
    code_parts = []
    for char in word:
        wubi_code = wubi86_8105_map[char]
        if len(wubi_code) == 3:
            code_parts.append(f"{wubi_code[:2]};{wubi_code[2:]}z")
        else:
            code_parts.append(f"{wubi_code[:2]};{wubi_code[2:]}")
    return ' '.join(code_parts)


@timer
def convert(src_dir: Path, out_dir: Path, file_endswith_filter: str) -> None:
    """å°†æ‹¼éŸ³è¯åº“è½¬æ¢ä¸ºäº”ç¬”è¯åº“"""
    out_dir.mkdir(parents=True, exist_ok=True)
    tab_split_re = re.compile(r'\t+')

    for file_num, file_path in enumerate(src_dir.glob(f'*{file_endswith_filter}'), 1):
        print(f'â˜‘ï¸  å·²åŠ è½½ç¬¬ {file_num} ä»½ç è¡¨ Â» {file_path.name}')

        valid_entries = set()
        invalid_line_count = 0

        with open(file_path, 'r', encoding='utf-8') as f:
            for line in f:
                line = line.strip()
                if not line or line[0] not in wubi86_8105_map:
                    continue

                parts = tab_split_re.split(line)
                if len(parts) < 3:
                    continue

                word, _, weight = parts[0], parts[1], parts[2]
                
                try:
                    wubi_code = get_wubi_code(word)
                    valid_entries.add(f"{word}\t{wubi_code}\t{weight}\n")
                except KeyError:
                    invalid_line_count += 1

        if valid_entries:
            output_path = out_dir / f"{file_path.stem}.yaml"
            with open(output_path, 'w', encoding='utf-8') as o:
                o.writelines(sorted(valid_entries))

            # print(f"  æˆåŠŸè½¬æ¢ {len(valid_entries)} æ¡è®°å½•ï¼Œè·³è¿‡ {invalid_line_count} æ¡æ— æ•ˆè®°å½•")


@timer
def filter_8105(src_dir: Path, out_file: Path):
    """è¿‡æ»¤å¹¶åˆå¹¶äº”ç¬”ç è¡¨ï¼Œä¿æŒæŒ‰è¯é•¿æ’åº"""
    dict_num = 0
    res_dict = {}
    tab_split_re = re.compile(r'\t+')
    word_len_groups = {}
    
    # æŒ‰è¯é•¿åˆ†ç»„å¤„ç†
    for filepath in src_dir.iterdir():
        if filepath.is_file():
            dict_num += 1
            print(f'â˜‘ï¸  å·²åŠ è½½ç¬¬ {dict_num} ä»½ç è¡¨ Â» {filepath.name}')
            
            with open(filepath, 'r', encoding='utf-8') as f:
                for line in f:
                    if not line or line[0] not in wubi86_8105_map:
                        continue
                        
                    parts = tab_split_re.split(line.strip())
                    if len(parts) < 2:
                        continue
                        
                    word, code = parts[0], parts[1]
                    weight = parts[2] if len(parts) >= 3 else '0'
                    word_len = len(word)
                    
                    try:
                        if word not in res_dict:
                            res_dict[word] = {code}
                            if word_len not in word_len_groups:
                                word_len_groups[word_len] = []
                            word_len_groups[word_len].append(f"{word}\t{code}\t{weight}\n")
                        elif code not in res_dict[word]:
                            res_dict[word].add(code)
                            if word_len not in word_len_groups:
                                word_len_groups[word_len] = []
                            word_len_groups[word_len].append(f"{word}\t{code}\t{weight}\n")
                    except KeyError:
                        continue
    
    print('\nğŸ”œ  --- æ­£åœ¨åˆå¹¶å¤„ç†è¯åº“æ–‡ä»¶ ---')
    
    # æŒ‰è¯é•¿æ’åºå¹¶æ”¶é›†ç»“æœ
    output_lines = []
    line_count_sum = 0
    for word_len in sorted(word_len_groups.keys()):
        group_lines = word_len_groups[word_len]
        output_lines.extend(group_lines)
        line_count_sum += len(group_lines)
        print(f'âœ…  Â» å·²åˆå¹¶å¤„ç†ç”Ÿæˆ {word_len} å­—è¯è¯­ï¼Œå…±è®¡ {len(group_lines)} è¡Œ')
    
    print(f'â˜‘ï¸  å…±ç”Ÿæˆ {line_count_sum} è¡Œæ•°æ®')
    
    # å†™å…¥è¾“å‡ºæ–‡ä»¶
    out_file.parent.mkdir(parents=True, exist_ok=True)
    if out_file.exists():
        out_file.unlink()
        
    with open(out_file, 'w', encoding='utf-8') as o:
        o.write(get_header_zj(out_file.name))
        o.writelines(output_lines)


# æ’åºç°æœ‰æ ‡å‡†è¯åº“
# created by Jack Liu <https://aituyaa.com>
# 
from pathlib import Path
from header import get_header_sort
from timer import timer




def get_md5(text: str) -> str:
    """è®¡ç®—å­—ç¬¦ä¸²çš„ MD5 å“ˆå¸Œå€¼"""
    md5 = hashlib.md5()  # åˆ›å»º MD5 å¯¹è±¡
    md5.update(text.encode('utf-8'))  # ä¼ å…¥å­—èŠ‚æ•°æ®ï¼ˆå¿…é¡» encodeï¼‰
    return md5.hexdigest()  # è¿”å› 32 ä½ 16 è¿›åˆ¶å­—ç¬¦ä¸²

@timer
def combine(src_dir, out_dir, dict_start):
    res_dict = {}
    lines_total = []

    # åŠ è½½æ‰€æœ‰è¯å…¸æ–‡ä»¶
    for file_path in src_dir.iterdir():
        if file_path.is_file() and file_path.name.startswith(dict_start):
            with open(file_path, 'r', encoding='utf-8') as f:
                lines_total.extend(f.readlines())

    # ä¿ç•™åŸæœ‰è¯å…¸è¡¨å¤´
    header_str = ''
    is_header_end = False
    for line in lines_total:
        if line.startswith('.'):
            is_header_end = True
        if line[0] not in wubi86_8105_map and not is_header_end:
            header_str += line 


    # å»é‡å¹¶å¤„ç†è¯æ¡
    for line in set(lines_total):
        if line[0] in wubi86_8105_map:
            word, code, weight = line.strip().split('\t')
            weight = int(weight)
            
            # å”¯ä¸€åŒ–
            if word not in res_dict:
                res_dict[word + get_md5(line)] = f'{code}\t{weight}'


    # å¤šçº§åˆ†ç»„æ’åºï¼ˆè¯é•¿â†’ç¼–ç é•¿åº¦â†’ç¼–ç â†’æ±‰å­—ï¼‰
    with open(out_dir / f'{dict_start}.dict.yaml', 'w', encoding='utf-8') as o:
        o.write(header_str)
        # o.write(get_header_sort(out_file))
        o.write('...\n')
        
        # ç¬¬ä¸€çº§ï¼šæŒ‰è¯é•¿åˆ†ç»„
        word_len_dict = defaultdict(list)
        for word, value in res_dict.items():
            word_len_dict[len(word)].append((word, value))

        # å¤„ç†æ¯ç»„è¯é•¿
        for word_len in sorted(word_len_dict.keys()):
            # ç¬¬äºŒçº§ï¼šæŒ‰ç¼–ç é•¿åº¦åˆ†ç»„
            code_len_dict = defaultdict(list)
            for word, value in word_len_dict[word_len]:
                code = value.split('\t')[0]
                code_len_dict[len(code)].append((word, code, value))

            # æŒ‰ç¼–ç é•¿åº¦å¤„ç†
            for code_len in sorted(code_len_dict.keys()):
                # å…³é”®ä¿®æ”¹ï¼šå½“ç¼–ç ç›¸åŒæ—¶ï¼ŒæŒ‰æ±‰å­—unicodeæ’åº
                group = sorted(code_len_dict[code_len], 
                             key=lambda x: (x[1], x[0]))  # å…ˆæŒ‰ç¼–ç æ’åºï¼Œå†æŒ‰æ±‰å­—æ’åº
                for word, _, value in group:
                    o.write(f'{word[:-32]}\t{value}\n')
            print(f'âœ… å·²æ’åºå¤„ç†ç”Ÿæˆ {word_len - 32} å­—è¯è¯­')
        print('â˜‘ï¸  Â» å·²æ’åºç”Ÿæˆç”¨æˆ·è¯å…¸ %s' % (out_dir / f'{dict_start}.dict.yaml'))




if __name__ == "__main__":
    proj_dir = Path(__file__).resolve().parent.parent
    work_dir = ".temp"
    
    # åŒæ­¥ä»“åº“
    repository_url = "https://github.com/amzxyz/rime_wanxiang.git"
    local_directory = proj_dir / work_dir / "rime_wanxiang"
    print('ğŸ”œ  === å¼€å§‹è·å–æœ€æ–°è¯åº“æ–‡ä»¶ ===')
    sync_repository(repository_url, local_directory)

    # è½¬æ¢æ‹¼éŸ³è¯åº“ä¸ºäº”ç¬”è¯åº“
    src_dir = proj_dir / work_dir / 'rime_wanxiang/cn_dicts'
    out_dir = proj_dir / work_dir / 'cn_dicts_x'
    print('\nğŸ”œ  === å¼€å§‹åŒæ­¥è½¬æ¢è¯åº“æ–‡ä»¶ ===')
    convert(src_dir, out_dir, '.dict.yaml')

    # è¿‡æ»¤åˆå¹¶äº”ç¬”ç è¡¨
    src_dir = proj_dir / work_dir / 'cn_dicts_x'
    out_file = proj_dir / work_dir / 'wubi86_zj.dict.yaml'
    print('\nğŸ”œ  === å¼€å§‹åˆå¹¶å¤„ç†è¯åº“æ–‡ä»¶ ===')
    filter_8105(src_dir, out_file)

    
    src_dir = proj_dir /  work_dir
    out_dir = proj_dir / 'dicts'
    dict_start = 'wubi86_zj'
    print('\nğŸ”œ  === å¼€å§‹æ’åºå¤„ç†è¯åº“æ–‡ä»¶ ===')
    # æ’åºå¤„ç†è‡³ç”¨æˆ·è¯å…¸
    combine(src_dir, out_dir, dict_start)